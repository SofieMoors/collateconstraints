{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: collatex in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (2.2)\n",
      "Requirement already satisfied: prettytable in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (from collatex) (3.8.0)\n",
      "Requirement already satisfied: networkx in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (from collatex) (3.1)\n",
      "Requirement already satisfied: wcwidth in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (from prettytable->collatex) (0.2.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade collatex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lxml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstring\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sub\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlxml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m etree\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01metree\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mElementTree\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mET\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lxml'"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "from itertools import combinations\n",
    "import string\n",
    "from re import sub\n",
    "\n",
    "from lxml import etree\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "!pip install graphviz \n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'Ant',\n",
       " 'B',\n",
       " 'BR',\n",
       " 'C',\n",
       " 'D',\n",
       " 'D2',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'Ge',\n",
       " 'K',\n",
       " 'L',\n",
       " 'O',\n",
       " 'W',\n",
       " 'Y',\n",
       " 'Z']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigles = [os.path.basename(fn).replace('xml_', '').replace('.xml', '') for fn in glob('../data/xml_martijn/*.xml')]\n",
    "sigles = sorted(sigles)\n",
    "sigles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gap_lines(tree):\n",
    "    gap_lines = []\n",
    "    for text in tree.iterfind('.//'+\"{\"+ NSMAP[\"MVN\"]+ \"}\"+'text'):\n",
    "        if 'n' in text.attrib:\n",
    "            for line in text.iterfind('.//'+\"{\"+ NSMAP[\"MVN\"]+ \"}\"+'l'):\n",
    "                if(line.find('.//'+\"{\"+ NSMAP[\"MVN\"]+ \"}\"+'gap')) is not None:\n",
    "                    gap_lines.append(text.attrib['n'] + '-' + line.attrib['n'])\n",
    "    return gap_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSMAP = {'MVN': 'http://www.tei-c.org/ns/1.0'}\n",
    "removes = ('teiHeader', 'fw', 'supplied', 'abbr') \n",
    "removes_expan_false = ('teiHeader', 'fw', 'supplied', 'ex', 'expan')\n",
    "\n",
    "chars = {'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', \n",
    "         'k', 'l','m', 'n', 'o', 'p', 'q', 'r', 's', 't', \n",
    "         'u', 'v', 'w', 'x', 'y', 'z'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704\n",
      "-> removed 162 lines with gaps\n",
      "539\n"
     ]
    }
   ],
   "source": [
    "def extract_lines(xml_file, expan = True, punct = True, lower = True): #added a 'flag' to the extraction function --> if... else\n",
    "    lines = {}\n",
    "    tree = etree.parse(xml_file)\n",
    "    \n",
    "    if expan:\n",
    "        #delete all elements with the provided tag names from a tree or subtree\n",
    "        #will also remove the tail text unless explicitly set the with_tail keyword argument option to False\n",
    "        etree.strip_elements(tree, (\"{\"+ NSMAP[\"MVN\"]+ \"}\" + s for s in removes), with_tail=False) \n",
    "    else: \n",
    "        etree.strip_elements(tree, (\"{\"+ NSMAP[\"MVN\"]+ \"}\" + s for s in removes_expan_false), with_tail=False)\n",
    "            \n",
    "    context = etree.iterwalk(tree, events=(\"start\", \"end\")) #a tree walker generates events from an existing tree. 'Start' and 'end' represent opening and closing elements\n",
    "    #u prefix indicates Unicode\n",
    "    text = u\"\" \n",
    "    #this will be the key in the dictionary of lines {}\n",
    "    k = '' \n",
    "    for action, node in context:\n",
    "        #remove ns for easier access\n",
    "        #tag_only bevat de tags op een knooppunt\n",
    "        #.tag selects all child elements with the given tag. A tag is a string identifying what kind of data this element represents (the element type, in other words).\n",
    "        #.replace removes ns www.tei...\n",
    "        \n",
    "        tag_only = node.tag.replace(\"{http://www.tei-c.org/ns/1.0}\",\"\") \n",
    "            \n",
    "        #node.attrib: XML elements have attributes \n",
    "        #attrib is a dictionary containing the element’s attributes. \n",
    "        if 'n' in node.attrib and tag_only == 'text': \n",
    "            title = node.attrib['n'] #for example Eerste Martijn\n",
    "        \n",
    "        if 'n' in node.attrib and tag_only == \"l\":                \n",
    "            k = title + '-' + node.attrib['n'] #for example 001, 002, 003...\n",
    "  \n",
    "        # if a new pb (standalone element) is processed:\n",
    "        if action == 'start' and tag_only == 'text': \n",
    "            continue\n",
    "            \n",
    "        # if new lb (standalone) is processed:\n",
    "        elif action == 'start' and tag_only == 'lb':\n",
    "            continue\n",
    "\n",
    "        # list elements which you want to iterate through. this is not really neccessary.\n",
    "        elif tag_only in (\"group\",\"text\",\"MVN\",\"body\",\"cb\",\"p\"):\n",
    "            continue\n",
    "\n",
    "        # for all other elements, distinguish between the start-event of the processing and\n",
    "        # and the end-event. Attach the tail AFTER the child nodes were processed (= end-event) \n",
    "\n",
    "        elif action == 'start':\n",
    "            #comment the following two lines out to not get the element markers\n",
    "            #f.write(f\"[{tag_only}]\") \n",
    "            #text += f\"[{tag_only}]\"\n",
    "\n",
    "            ############################################################################\n",
    "            ########## filter out special characters, bars,                   ##########\n",
    "            ########## superscript, or specific tags.                         ##########\n",
    "            ############################################################################\n",
    "            \n",
    "            #if a special glyph is present, encode it accordingly\n",
    "            \n",
    "            replacements = {\"a\": u'\\u0101', 'A': u'\\u0100', 'e': u'\\u0113', 'E': u'\\u0112','n': u'\\u00F1','N': u'\\u00D1','o': u'\\u014D',\n",
    "                    'O': u'\\u014C','u': u'\\u016B','U': u'\\u016A','i': u'\\u012B','I': u'\\u012A','j': u'\\u025F', 'J': u'\\u0248', 'm': u'\\u1E3F',\n",
    "                    'M': u'\\u1E3E','Y': u'\\u0232','y': u'\\u0233', 'h': u'\\uE517', 'p': u'\\u1E55'}\n",
    "            \n",
    "            if tag_only == 'g':\n",
    "\n",
    "                #if 'ref' in node.attrib and node.attrib['ref'] == '#bar':\n",
    "                if node.attrib['ref'] == '#bar': # ā, ē, ī, ō, ū, n̄ etc.\n",
    "                    if text[-1] in replacements: # if final letter before #bar is in replacement dict\n",
    "                        for key, value in replacements.items(): # loop over all key-value pairs\n",
    "                            text = text[:-1] + text[-1].replace(key, value) # replace text with text starting at beginning up until that letter, then add decomp character\n",
    "                                     \n",
    "                            \n",
    "                elif node.attrib['ref'] == '#apomod': # ʼ\n",
    "                    text += u'\\u02bc'\n",
    "\n",
    "                elif node.attrib['ref'] == '#usmod': # ꝰ\n",
    "                    text += u'\\ua770'\n",
    "\n",
    "                elif node.attrib['ref'] == '#condes': # ꝯ\n",
    "                    text += u'\\ua76f'\n",
    "\n",
    "                elif node.attrib['ref'] == '#para': # ¶\n",
    "                    text += u'\\xb6'\n",
    "\n",
    "                elif node.attrib['ref'] == '#etfin': # ꝫ\n",
    "                    text += u'\\ua76b'\n",
    "\n",
    "                elif node.attrib['ref'] == '#pbardes': # ꝑ\n",
    "                    text += u'\\ua751'\n",
    "\n",
    "                elif node.attrib['ref'] == '#pbardes': # ꝕ\n",
    "                    text += u'\\ua755'\n",
    "\n",
    "                elif node.attrib['ref'] == '#pflour': # ꝓ\n",
    "                    text += u'\\ua753'\n",
    "\n",
    "                else:\n",
    "                    node.attrib['ref']\n",
    "                    text += str(node.attrib['ref']) # get the actual ref if there still are any left\n",
    "\n",
    "            #encode superscript letters\n",
    "            superscript_dict = {'a':'ᵃ', 'b':'ᵇ', 'c':'ᶜ', 'd':'ᵈ', 'e':'ᵉ', 'f':'ᶠ',\n",
    "                               'g':'ᵍ', 'h':'ʰ', 'i':'ᶦ', 'j':'ʲ', 'k':'ᵏ', 'l':'ˡ', \n",
    "                                'm':'ᵐ', 'n':'ⁿ', 'o':'ᵒ', 'p':'ᵖ', 'r':'ʳ', 's':'ˢ', \n",
    "                                't':'ᵗ', 'u':'ᵘ', 'v':'ᵛ', 'w':'ʷ', 'x':'ˣ', 'y': 'ʸ', 'z': 'ᶻ'}\n",
    "\n",
    "            if tag_only == 'hi' and 'rend' in node.attrib and node.attrib['rend'] == 'superscript': #rend(ition) supplies information about the appearance of an element\n",
    "                if node.text in superscript_dict:\n",
    "                    text += str(superscript_dict[node.text]).strip()\n",
    "\n",
    "            #encode punctuation marks\n",
    "            elif tag_only == 'pc':\n",
    "                text += str(node.text).strip()\n",
    "\n",
    "            #encode roman numerals\n",
    "            elif tag_only == 'num':\n",
    "                if node.text:\n",
    "                    text += str('.'+node.text+'.').strip()\n",
    "\n",
    "            #if there is still a node with text in it\n",
    "            elif (node.text):\n",
    "                text += node.text        \n",
    "\n",
    "        #after the child elements\n",
    "        elif action == 'end':\n",
    "            #if there is a tail\n",
    "            #the tail attribute holds the text between the element’s end tag and the next tag, or None\n",
    "            if (node.tail and node.tail not in \"\\t\"): #if the tail is not yet in the text \n",
    "                #comment the following two lines out to not get the tail marker\n",
    "                #text += \"[tail]\"\n",
    "                #f.write(\"[tail]\")\n",
    "                #append to text-concatenation\n",
    "                text += str(node.tail)\n",
    "        if tag_only == 'lb':\n",
    "            if k:\n",
    "                text = sub(r'\\n', '', text) #when an \"r\" prefix is present, a character following a backslash is included in the string/all backslashes are left in string. \n",
    "                if not punct:\n",
    "                    text = text.translate(str.maketrans('', '', string.punctuation)) #the value of the keys k is the text \n",
    "                if lower: \n",
    "                    text = text.lower()\n",
    "                   \n",
    "                    # text = text[::-1]\n",
    "                  \n",
    "                lines[k] = text #the value of the keys k is the text \n",
    "                text = ''\n",
    "    \n",
    "    # catch dangling last line (if applicable):\n",
    "    if text:\n",
    "        lines[k] = text\n",
    "    \n",
    "    # remove empty lines:\n",
    "    num_orig_lines = len(lines)\n",
    "    print(num_orig_lines)\n",
    "    # remove lines with gaps:\n",
    "    gap_lines = get_gap_lines(tree)\n",
    "    #print(gap_lines)\n",
    "    lines = {k:v for k, v in lines.items() if k not in gap_lines}\n",
    "    print(f'-> removed {num_orig_lines - len(lines)} lines with gaps')\n",
    "    \n",
    "    \n",
    "   \n",
    "    lines = {k:v for k, v in lines.items() if v.strip()}\n",
    "    return lines\n",
    "\n",
    "# lowercasen (flag) en interpunctie weghalen\n",
    "d = extract_lines(f'../data/xml_martijn/xml_{sigles[12]}.xml', expan = False, punct = False, lower = True)\n",
    "#print(d)\n",
    "print(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 9/17 [00:00<00:00, 36.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770\n",
      "-> removed 5 lines with gaps\n",
      "104\n",
      "-> removed 104 lines with gaps\n",
      "1821\n",
      "-> removed 0 lines with gaps\n",
      "608\n",
      "-> removed 22 lines with gaps\n",
      "1472\n",
      "-> removed 0 lines with gaps\n",
      "1824\n",
      "-> removed 0 lines with gaps\n",
      "247\n",
      "-> removed 99 lines with gaps\n",
      "276\n",
      "-> removed 0 lines with gaps\n",
      "1823\n",
      "-> removed 0 lines with gaps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 36.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1768\n",
      "-> removed 0 lines with gaps\n",
      "152\n",
      "-> removed 74 lines with gaps\n",
      "67\n",
      "-> removed 0 lines with gaps\n",
      "704\n",
      "-> removed 162 lines with gaps\n",
      "1824\n",
      "-> removed 0 lines with gaps\n",
      "507\n",
      "-> removed 0 lines with gaps\n",
      "361\n",
      "-> removed 84 lines with gaps\n",
      "542\n",
      "-> removed 7 lines with gaps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mss = {}\n",
    "\n",
    "for sigle in tqdm(sigles):\n",
    "    mss[sigle] = extract_lines(f'../data/xml_martijn/xml_{sigle}.xml', expan = False, punct = False, lower = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_input(sigles, mss):\n",
    "    input = {}\n",
    "    for i in sigles:\n",
    "        for line_name in mss[i]:\n",
    "            if line_name not in input:\n",
    "                input[line_name] = [{\"id\": i, \"content\": mss[i][line_name]}]\n",
    "            else:\n",
    "                input[line_name] += [{\"id\": i, \"content\": mss[i][line_name]}]\n",
    "    return input\n",
    "\n",
    "input = transform_input(sigles, mss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# send to collatex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#useful website: http://interedition.github.io/collatex/  .html\n",
    "import json\n",
    "from collatex import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_collatex(input):  # stuur van elke versie 1 regel door\n",
    "    import sys \n",
    "    stdoutOrigin=sys.stdout \n",
    "    sys.stdout = open(\"log.json\", \"w\")\n",
    "    output = {}\n",
    "    collation = Collation()\n",
    "    \n",
    "\n",
    "    for i in input:\n",
    "        if i in [\"Tweede Martijn-001\", \"Tweede Martijn-002\", \"Tweede Martijn-003\"]: #hier als voorbeeld enkel de eerste 3 lijnen in de dictionary naar collatex sturen, de anderen worden genegeerd.\n",
    "            print(str(input[i]))\n",
    "        json_input = \"\"\"{\"witnesses\": \"\"\" + str(input[i]) + \"}\"\n",
    "        json_input = re.sub(r\"\\'\", \"\\\"\", json_input)\n",
    "        \n",
    "        \n",
    "        output[i] = str(collate(json.loads(json_input), \n",
    "                                    layout=\"vertical\", \n",
    "                                    near_match=True, \n",
    "                                    segmentation=False, \n",
    "                                    output='json',\n",
    "                                   ))\n",
    "        \n",
    "        print(collate(json.loads(json_input),\n",
    "                                    layout=\"horizontal\", \n",
    "                                    near_match=True, \n",
    "                                    segmentation=False, \n",
    "                                    output=\"json\",   \n",
    "                                    \n",
    "                                ))\n",
    "       \n",
    "    return output\n",
    "    sys.stdout.close()\n",
    "    sys.stdout=stdoutOrigin\n",
    "\n",
    "    \n",
    "test = send_to_collatex(input)\n",
    "print(test[\"Tweede Martijn-003\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
