{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to convert MVN-xml file to plain txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/xml_martijn/xml_Ge.xml\n",
      "../data/xml_martijn/xml_F.xml\n",
      "../data/xml_martijn/xml_D.xml\n",
      "../data/xml_martijn/xml_E.xml\n",
      "../data/xml_martijn/xml_A.xml\n",
      "../data/xml_martijn/xml_W.xml\n",
      "../data/xml_martijn/xml_B.xml\n",
      "../data/xml_martijn/xml_C.xml\n",
      "../data/xml_martijn/xml_Y.xml\n",
      "../data/xml_martijn/xml_O.xml\n",
      "../data/xml_martijn/xml_Z.xml\n",
      "../data/xml_martijn/xml_L.xml\n",
      "../data/xml_martijn/xml_BR.xml\n",
      "../data/xml_martijn/xml_K.xml\n",
      "../data/xml_martijn/xml_Ant.xml\n",
      "../data/xml_martijn/xml_D2.xml\n"
     ]
    }
   ],
   "source": [
    "xml_path = '../data/xml_martijn'\n",
    "\n",
    "file_paths = []\n",
    "\n",
    "for root, dirs, files in os.walk(xml_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\"checkpoint.xml\"): # disregard files generated by checkpoints\n",
    "            continue\n",
    "        if file == 'charDecl.xml': # disregard charDecl\n",
    "            continue\n",
    "        if file.endswith(\".xml\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_paths.append(file_path)\n",
    "            print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xml_Ge\n",
      "xml_F\n",
      "xml_D\n",
      "xml_E\n",
      "xml_A\n",
      "xml_W\n",
      "xml_B\n",
      "xml_C\n",
      "xml_Y\n",
      "xml_O\n",
      "xml_Z\n",
      "xml_L\n",
      "xml_BR\n",
      "xml_K\n",
      "xml_Ant\n",
      "xml_D2\n"
     ]
    }
   ],
   "source": [
    "for file_path in file_paths:\n",
    "    file_name = os.path.basename(file_path)\n",
    "    variant_name = file_name.split('.')[0]\n",
    "    print(variant_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xml_Ge\n",
      "xml_F\n",
      "xml_D\n",
      "xml_E\n",
      "xml_A\n",
      "xml_W\n",
      "xml_B\n",
      "xml_C\n",
      "xml_Y\n",
      "xml_O\n",
      "xml_Z\n",
      "xml_L\n",
      "xml_BR\n",
      "xml_K\n",
      "xml_Ant\n",
      "xml_D2\n"
     ]
    }
   ],
   "source": [
    "# saving edited xml as tmp.xml\n",
    "for file_path in file_paths:\n",
    "    file_name = os.path.basename(file_path)\n",
    "    variant_name = file_name.split('.')[0]\n",
    "    print(variant_name)\n",
    "    plain_file_name = variant_name.split('_')[1] # this is the name of the variant (used to name the plain txt file)\n",
    "\n",
    "    with open(f\"../data/xml_martijn/{variant_name}.xml\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    #text = text.replace('<choice>', '')\n",
    "    #text = text.replace('</choice>', '')\n",
    "\n",
    "    with open(f\"../data/tmp/tmp_{variant_name}.xml\", 'w', encoding='utf-8') as f:\n",
    "        f.write(text)\n",
    "        \n",
    "    tree = etree.parse(f'../data/tmp/tmp_{variant_name}.xml')\n",
    "\n",
    "    NSMAP = {'MVN': 'http://www.tei-c.org/ns/1.0'}\n",
    "    removes = ('teiHeader', 'fw', 'supplied', 'ex', 'expan') \n",
    "    etree.strip_elements(tree, (\"{\"+ NSMAP[\"MVN\"]+ \"}\" + s for s in removes), with_tail=False)\n",
    "\n",
    "\n",
    "    chars = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', \n",
    "             'k', 'l','m', 'n', 'o', 'p', 'q', 'r', 's', 't', \n",
    "             'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "    text = \"\"\n",
    "\n",
    "    #folia = []\n",
    "\n",
    "    context = etree.iterwalk(tree, events=(\"start\", \"end\"))\n",
    "    for action, node in context:\n",
    "\n",
    "        # remove ns for easier access\n",
    "        tag_only = node.tag.replace(\"{http://www.tei-c.org/ns/1.0}\",\"\")\n",
    "\n",
    "        # if a new pb (standalone element) is processed:\n",
    "        if action == 'start' and tag_only == 'text':\n",
    "            #..close file if open already (always true except for first page)\n",
    "            if f:\n",
    "                f.close() \n",
    "            #..open new file to write in\n",
    "\n",
    "            f = open(f'../data/plain_txt_martijn/{plain_file_name}.txt', 'w', encoding=\"utf-8\")\n",
    "            #f.write(f\"\\n[page: %{node.attrib['n']}]\\n\")\n",
    "            #text += f\"\\n[page: %{node.attrib['n']}]\\n\"\n",
    "\n",
    "            #folia.append(node.attrib[\"n\"])\n",
    "\n",
    "        # if new lb (standalone) is processed:\n",
    "        elif action == 'start' and tag_only == 'lb':\n",
    "            continue\n",
    "            #f.write(\"\\n\")\n",
    "            #text += \"\\n\"\n",
    "\n",
    "        # list elements which you want to iterate through. this is not really neccessary.\n",
    "        elif tag_only in (\"group\",\"text\",\"MVN\",\"body\",\"cb\",\"p\"):\n",
    "            continue\n",
    "\n",
    "        # for all other elements, distinguish between the start-event of the processing and\n",
    "        # and the end-event. Attach the tail AFTER the child nodes were processed (=end-event) \n",
    "\n",
    "        elif action == 'start':\n",
    "            # comment the following two lines out to not get the element markers\n",
    "            #f.write(f\"[{tag_only}]\") \n",
    "            #text += f\"[{tag_only}]\"\n",
    "\n",
    "            ############################################################################\n",
    "            ########## filter out special characters, bars,                   ##########\n",
    "            ########## superscript, or specific tags.                         ##########\n",
    "            ############################################################################\n",
    "\n",
    "            # if a special glyph is present, encode it accordingly\n",
    "            if tag_only == 'g':\n",
    "\n",
    "                if node.attrib['ref'] == '#bar': # ā, ē, ī, ō, ū, n̄ etc.\n",
    "                    f.write(u'\\u0304')\n",
    "                    text += u'\\u0304'\n",
    "\n",
    "                elif node.attrib['ref'] == '#apomod': # ʼ\n",
    "                    f.write(u'\\u02bc')\n",
    "                    text += u'\\u02bc'\n",
    "\n",
    "                elif node.attrib['ref'] == '#usmod': # ꝰ\n",
    "                    f.write(u'\\ua770')\n",
    "                    text += u'\\ua770'\n",
    "\n",
    "                elif node.attrib['ref'] == '#condes': # ꝯ\n",
    "                    f.write(u'\\ua76f')\n",
    "                    text += u'\\ua76f'\n",
    "\n",
    "                elif node.attrib['ref'] == '#para': # ¶\n",
    "                    f.write(u'\\xb6')\n",
    "                    text += u'\\xb6'\n",
    "\n",
    "                elif node.attrib['ref'] == '#etfin': # ꝫ\n",
    "                    f.write(u'\\ua76b')\n",
    "                    text += u'\\ua76b'\n",
    "\n",
    "                elif node.attrib['ref'] == '#pbardes': # ꝑ\n",
    "                    f.write(u'\\ua751')\n",
    "                    text += u'\\ua751'\n",
    "\n",
    "                elif node.attrib['ref'] == '#pbardes': # ꝕ\n",
    "                    f.write(u'\\ua755')\n",
    "                    text += u'\\ua755'\n",
    "\n",
    "                elif node.attrib['ref'] == '#pflour': # ꝓ\n",
    "                    f.write(u'\\ua753')\n",
    "                    text += u'\\ua753'\n",
    "\n",
    "                else:\n",
    "                    f.write(node.attrib['ref']) # get the actual ref if there still are any left\n",
    "                    text += node.attrib['ref']\n",
    "\n",
    "            # encode superscript letters\n",
    "            superscript_dict = {'a':'ᵃ', 'b':'ᵇ', 'c':'ᶜ', 'd':'ᵈ', 'e':'ᵉ', 'f':'ᶠ',\n",
    "                               'g':'ᵍ', 'h':'ʰ', 'i':'ᶦ', 'j':'ʲ', 'k':'ᵏ', 'l':'ˡ', \n",
    "                                'm':'ᵐ', 'n':'ⁿ', 'o':'ᵒ', 'p':'ᵖ', 'r':'ʳ', 's':'ˢ', \n",
    "                                't':'ᵗ', 'u':'ᵘ', 'v':'ᵛ', 'w':'ʷ', 'x':'ˣ', 'y': 'ʸ', 'z': 'ᶻ'}\n",
    "\n",
    "            if tag_only == 'hi' and 'rend' in node.attrib and node.attrib['rend'] == 'superscript':\n",
    "                if node.text in superscript_dict:\n",
    "                    f.write(superscript_dict[node.text])\n",
    "                    text += superscript_dict[node.text]\n",
    "\n",
    "            # encode punctuation marks\n",
    "            elif tag_only == 'pc':\n",
    "                f.write(node.text)\n",
    "                text += (node.text)\n",
    "\n",
    "            # encode roman numerals\n",
    "            elif tag_only == 'num':\n",
    "                if node.text:\n",
    "                    f.write('.'+node.text+'.')\n",
    "                    text += ('.'+node.text+'.')\n",
    "\n",
    "            # if there is still a node with text in it\n",
    "            elif (node.text):\n",
    "                f.write(node.text)\n",
    "                text += node.text\n",
    "\n",
    "        # after the child elements\n",
    "        elif action == 'end':\n",
    "            # if there is a tail\n",
    "            if (node.tail and node.tail not in \"\\t\"):\n",
    "                # comment the folowing two lines out to not get the tail marker\n",
    "                #text += \"[tail]\"\n",
    "                #f.write(\"[tail]\")\n",
    "                # write the tail text into the file & append to text-concatenation\n",
    "                text += node.tail\n",
    "                f.write(node.tail)\n",
    "    #f.close()\n",
    "\n",
    "    #print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ʼ\n"
     ]
    }
   ],
   "source": [
    "print(u'\\u02bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(u'\\ua755')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b' \\\\u0304'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=' ̄'\n",
    "s.encode(\"unicode_escape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\\\u02bc'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s='ʼ'\n",
    "s.encode(\"unicode_escape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
